{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef75b03-27f9-4d9f-b095-3fbc5ab9e1ec",
   "metadata": {},
   "source": [
    "Purpose: Collect historical tweets using the search tweet function offered through the Academic Twitter API.  Collect a max of 100,000 tweets for each month per year. Export into a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f87a12-526c-498e-b49d-f3454e6891ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import dateutil.parser\n",
    "import time \n",
    "import pandas as pd \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbce7c2-e02d-404e-8df0-614a4bdcbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth():\n",
    "    return os.getenv('TWITTER_BEARER_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe03ee-a9c8-45d2-bc00-f84601a1763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\" : \"Bearer {}\".format(bearer_token)}\n",
    "    return headers \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47e6dd-b6ad-4529-8670-8eda410bfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters \n",
    "\n",
    "def create_params(start_date, end_date, max_results):\n",
    "\n",
    "    query_params= {'query': 'bitcoin -is:retweet -is:quote -has:cashtags -has:media -has:links -has:videos -has:images -is:nullcast lang:en', \n",
    "                'start_time': start_date,\n",
    "                'end_time':end_date, \n",
    "                'max_results': '500',\n",
    "               'tweet.fields': 'text,created_at,public_metrics,in_reply_to_user_id',\n",
    "               'user.fields':'verified',\n",
    "               'next_token':{}}\n",
    "    return query_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9f782-9f97-4481-8f6a-363de9f390e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token\n",
    "    response = requests.request(\"GET\", search_url, auth=bearer_oauth, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c4bbf-797f-4a32-984c-e8c900050b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2FullArchiveTweetCountsPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "  \n",
    "#create file \n",
    "csvFile = open(\"2014Data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter=csv.writer(csvFile)\n",
    "\n",
    "#Create headers for the data \n",
    "csvWriter.writerow(['created_at', 'text', 'like_count', 'retweet_count', 'quote_count', 'reply_count'])\n",
    "csvFile.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea38ec-6353-4c4b-ae85-a2967f3d18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that appends the json_response to a csv file \n",
    "\n",
    "def append_to_csv(json_response, fileName):\n",
    "    \n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(\"2014Data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in json_response['data']:\n",
    "        \n",
    "        # We will create a variable for each since some of the keys might not exist for some tweets\n",
    "        # So we will account for that\n",
    "\n",
    "        # 2. Time created\n",
    "        created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "        \n",
    "        retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        reply_count = tweet['public_metrics']['reply_count']\n",
    "        like_count = tweet['public_metrics']['like_count']\n",
    "        quote_count = tweet['public_metrics']['quote_count']\n",
    "\n",
    "        # 8. Tweet text\n",
    "        text = tweet['text']\n",
    "        \n",
    "        # Assemble all data in a list\n",
    "        res = [created_at, text, like_count, quote_count, reply_count, retweet_count]\n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2cacc-5853-46a0-ae95-4f39154f9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each month for a specific year and collect as many tweets as possible (with a max of 100,000) per month, that meet the query defined above \n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "        \n",
    "#Example: COUNT FOR 2014\n",
    "start_list = ['2014-01-01T00:00:00Z', '2014-02-01T00:00:00Z', '2014-03-01T00:00:00Z', '2014-04-01T00:00:00Z', '2014-05-01T00:00:00Z', '2014-06-01T00:00:00Z', '2014-07-01T00:00:00Z', '2014-08-01T00:00:00Z', '2014-09-01T00:00:00Z', '2014-10-01T00:00:00Z', '2014-11-01T00:00:00Z', '2014-12-01T00:00:00Z']\n",
    "end_list = ['2014-01-31T00:00:00Z', '2014-02-28T00:00:00Z', '2014-03-31T00:00:00Z', '2014-04-30T00:00:00Z', '2014-05-31T00:00:00Z', '2014-06-30T00:00:00Z', '2014-07-31T00:00:00Z', '2014-08-30T00:00:00Z', '2014-09-30T00:00:00Z', '2014-10-31T00:00:00Z', '2014-11-30T00:00:00Z', '2014-12-31T00:00:00Z']\n",
    "\n",
    "max_results = 500\n",
    "\n",
    "total_tweets = 0\n",
    "\n",
    "\n",
    "for i in range(0, len(start_list)): \n",
    "    \n",
    "    count = 0 \n",
    "    max_count = 100000\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    #Check if flag is true\n",
    "    while flag:\n",
    "        if count >= max_count: \n",
    "            break \n",
    "        print(\"--------------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        query_params = create_params(start_list[i], end_list[i], max_results)\n",
    "        json_response = connect_to_endpoint(search_url, headers, query_params, next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "        \n",
    "        if 'next_token' in json_response['meta']:\n",
    "                \n",
    "            # Save the token to use for next call\n",
    "            \n",
    "            next_token = json_response['meta']['next_token']\n",
    "            \n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv(json_response, \"2014Data.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                \n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv(json_response, \"2014Data.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)\n",
    "                \n",
    "            flag = False\n",
    "            next_token = None \n",
    "                \n",
    "                \n",
    "                \n",
    "        time.sleep(5)\n",
    "    #print(\"Total number of results: \", total_tweets)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5560dfb-1a39-4f47-bdab-ef30aa9147f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
